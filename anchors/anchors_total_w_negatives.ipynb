{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8bc168",
   "metadata": {},
   "source": [
    "# **Anchors on all requirement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "729a59dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from sklearn.metrics import accuracy_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1801e",
   "metadata": {},
   "source": [
    "**Define useful data-wrangling functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8de2d",
   "metadata": {},
   "source": [
    "function separating the name of the feature from the ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "93401316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor(a):\n",
    "    quoted_part = a.split(\"'\")[1]\n",
    "    rest = a.replace(f\"'{quoted_part}'\", '').replace(\"b\", '').strip()\n",
    "\n",
    "    return quoted_part, rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f100666",
   "metadata": {},
   "source": [
    "function creating the intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f0f91abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import inf\n",
    "\n",
    "def parse_range(expr: str):\n",
    "    expr = expr.strip().replace(\" \", \"\")\n",
    "    \n",
    "    patterns = [\n",
    "        (r\"^=(\\-?\\d+(\\.\\d+)?)$\", 'equals'),\n",
    "        (r\"^(>=|>)\\s*(-?\\d+(\\.\\d+)?)$\", 'lower'),\n",
    "        (r\"^(<=|<)\\s*(-?\\d+(\\.\\d+)?)$\", 'upper'),\n",
    "        (r\"^(-?\\d+(\\.\\d+)?)(<=|<){1,2}(<=|<)(-?\\d+(\\.\\d+)?)$\", 'between'),\n",
    "        (r\"^(-?\\d+(\\.\\d+)?)(>=|>){1,2}(>=|>)(-?\\d+(\\.\\d+)?)$\", 'reverse_between'),\n",
    "    ]\n",
    "    \n",
    "    for pattern, kind in patterns:\n",
    "        match = re.match(pattern, expr)\n",
    "        if match:\n",
    "            if kind == 'equals':\n",
    "                num = float(match.group(1))\n",
    "                return (num, num, True, True)\n",
    "            elif kind == 'lower':\n",
    "                op, num = match.group(1), float(match.group(2))\n",
    "                return (\n",
    "                    num,\n",
    "                    inf,\n",
    "                    op == '>=',\n",
    "                    False\n",
    "                )\n",
    "            elif kind == 'upper':\n",
    "                op, num = match.group(1), float(match.group(2))\n",
    "                return (\n",
    "                    -inf,\n",
    "                    num,\n",
    "                    False,\n",
    "                    op == '<='\n",
    "                )\n",
    "            elif kind == 'between':\n",
    "                low = float(match.group(1))\n",
    "                op1 = match.group(3)\n",
    "                op2 = match.group(4)\n",
    "                high = float(match.group(5))\n",
    "                return (\n",
    "                    low,\n",
    "                    high,\n",
    "                    op1 == '<=',\n",
    "                    op2 == '<='\n",
    "                )\n",
    "            elif kind == 'reverse_between':\n",
    "                high = float(match.group(1))\n",
    "                op1 = match.group(3)\n",
    "                op2 = match.group(4)\n",
    "                low = float(match.group(5))\n",
    "                return (\n",
    "                    low,\n",
    "                    high,\n",
    "                    op2 == '>=',\n",
    "                    op1 == '>='\n",
    "                )\n",
    "\n",
    "    raise ValueError(f\"Unrecognized format: {expr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828af6f4",
   "metadata": {},
   "source": [
    "funtion intersecting two given intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6544bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "def intersect(\n",
    "    a: Tuple[float, float, bool, bool],\n",
    "    b: Tuple[float, float, bool, bool]\n",
    ") -> Optional[Tuple[float, float, bool, bool]]:\n",
    "    \n",
    "    a_low, a_high, a_li, a_ui = a\n",
    "    b_low, b_high, b_li, b_ui = b\n",
    "\n",
    "    # Compute max of lower bounds\n",
    "    if a_low > b_low:\n",
    "        low, li = a_low, a_li\n",
    "    elif a_low < b_low:\n",
    "        low, li = b_low, b_li\n",
    "    else:\n",
    "        low = a_low\n",
    "        li = a_li and b_li\n",
    "\n",
    "    # Compute min of upper bounds\n",
    "    if a_high < b_high:\n",
    "        high, ui = a_high, a_ui\n",
    "    elif a_high > b_high:\n",
    "        high, ui = b_high, b_ui\n",
    "    else:\n",
    "        high = a_high\n",
    "        ui = a_ui and b_ui\n",
    "\n",
    "    # Check for empty intersection\n",
    "    if low > high:\n",
    "        return None\n",
    "    if low == high and not (li and ui):\n",
    "        return None\n",
    "\n",
    "    return (low, high, li, ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5573a",
   "metadata": {},
   "source": [
    "function that return the truth value of a num (val) being inside a given interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "25c6710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside(val, interval):\n",
    "    low, high, li, ui = interval\n",
    "    if li and ui:\n",
    "        return low <= val <= high\n",
    "    elif li and not ui:\n",
    "        return low <= val < high\n",
    "    elif not li and ui:\n",
    "        return low < val <= high\n",
    "    else:\n",
    "        return low < val < high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a99e48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_w_anchor(input, thresholds, feature_names):\n",
    "    out = np.zeros(input.shape[0])\n",
    "    \n",
    "    for i in range(input.shape[0]):\n",
    "        for j in range(len(thresholds)):\n",
    "            flag = True\n",
    "            out[i] = 1\n",
    "            for nk,k in enumerate(feature_names):\n",
    "                if k in thresholds[j]:\n",
    "                    if not (inside(input[i,nk], thresholds[j][k])):\n",
    "                        flag = False\n",
    "                        out[i] = 0\n",
    "                        break\n",
    "            if flag:\n",
    "                break\n",
    "            else:\n",
    "                flag = True\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab5760",
   "metadata": {},
   "source": [
    "**DF Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1ce34289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  5000\n",
      "Training dataset size:  (4000, 13)\n",
      "Validation dataset size:  (1000, 13)\n",
      "Training samples with all requirements satisfied:  (156, 9)\n",
      "Validation samples with all requirements satisfied:  (49, 9)\n",
      "Training samples with req_0 satisfied:  (1382, 9)\n",
      "Training samples with req_1 satisfied:  (723, 9)\n",
      "Training samples with req_2 satisfied:  (908, 9)\n",
      "Training samples with req_3 satisfied:  (1041, 9)\n",
      "Validation samples with req_0 satisfied:  (342, 9)\n",
      "Validation samples with req_1 satisfied:  (172, 9)\n",
      "Validation samples with req_2 satisfied:  (235, 9)\n",
      "Validation samples with req_3 satisfied:  (261, 9)\n"
     ]
    }
   ],
   "source": [
    "#meta parameters\n",
    "train_percentage = 80\n",
    "val_percentage = 20\n",
    "\n",
    "req_names = ['req_0', 'req_1', 'req_2', 'req_3']\n",
    "req_number = len(req_names)\n",
    "feature_names = ['cruise speed','image resolution','illuminance','controls responsiveness','power','smoke intensity','obstacle size','obstacle distance','firm obstacle']\n",
    "feature_number = len(feature_names)\n",
    "\n",
    "training_folder = '../datasets/dataset5000.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(training_folder)\n",
    "n_samples = df.shape[0]\n",
    "print(\"Number of samples: \", n_samples)\n",
    "\n",
    "#Split 80 20 the training dataset in training anda validation to have more similar data\n",
    "indices = np.arange(0,n_samples)\n",
    "np.random.seed(1234)\n",
    "indices = np.random.permutation(indices)\n",
    "\n",
    "training_indices = indices[0:int(n_samples*train_percentage/100)]\n",
    "validation_indices = indices[int(n_samples*train_percentage/100):]\n",
    "\n",
    "training_df = df.iloc[training_indices]\n",
    "validation_df = df.iloc[validation_indices]\n",
    "print('Training dataset size: ', training_df.shape)\n",
    "print('Validation dataset size: ', validation_df.shape)\n",
    "\n",
    "#select the samples that have all the requirements satisfied\n",
    "all_true_training = training_df[\n",
    "    (training_df['req_0'] == 1) &\n",
    "    (training_df['req_1'] == 1) &\n",
    "    (training_df['req_2'] == 1) &\n",
    "    (training_df['req_3'] == 1)\n",
    "].drop(columns=req_names)\n",
    "\n",
    "all_true_validation = validation_df[\n",
    "    (validation_df['req_0'] == 1) &\n",
    "    (validation_df['req_1'] == 1) &\n",
    "    (validation_df['req_2'] == 1) &\n",
    "    (validation_df['req_3'] == 1)\n",
    "].drop(columns=req_names)\n",
    "\n",
    "print('Training samples with all requirements satisfied: ', all_true_training.shape)\n",
    "print('Validation samples with all requirements satisfied: ', all_true_validation.shape)\n",
    "\n",
    "#select the samples that have at one specific requirement satisfied\n",
    "req_true_training = {}\n",
    "for r in req_names:\n",
    "    req_true_training[r] = training_df[training_df[r] == 1].drop(columns=req_names)\n",
    "    print('Training samples with {} satisfied: '.format(r), req_true_training[r].shape)\n",
    "\n",
    "req_true_validation = {}\n",
    "for r in req_names:\n",
    "    req_true_validation[r] = validation_df[validation_df[r] == 1].drop(columns=req_names)\n",
    "    print('Validation samples with {} satisfied: '.format(r), req_true_validation[r].shape)\n",
    "\n",
    "#create a csv with the new training data and save it\n",
    "training_df.to_csv('../datasets/training_dataset.csv', index=False)\n",
    "validation_df.to_csv('../datasets/validation_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6e53832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples with req_0 satisfied:  (1365,)\n",
      "Training samples with req_1 satisfied:  (725,)\n",
      "Training samples with req_2 satisfied:  (903,)\n",
      "Training samples with req_3 satisfied:  (1029,)\n"
     ]
    }
   ],
   "source": [
    "datasets = [] #will contain the datasets as needed by the anchor library\n",
    "feature_to_use = [i for i in range(feature_number)] #contains the range of features to use\n",
    "true_from_anchors_df = {}\n",
    "\n",
    "for i,r in enumerate(req_names):\n",
    "    #we load the dataset in anchors\n",
    "    datasets.append(\\\n",
    "        utils.load_csv_dataset(\\\n",
    "            training_folder, feature_number+i,\\\n",
    "            features_to_use=feature_to_use,\\\n",
    "            categorical_features=None))\n",
    "    \n",
    "    true_from_anchors_df[r] = np.nonzero(datasets[i].labels_train)[0]\n",
    "    print('Training samples with {} satisfied: '.format(r), true_from_anchors_df[r].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a955bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = '../datasets/training_dataset.csv'\n",
    "validation_folder = '../datasets/validation_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c01e6",
   "metadata": {},
   "source": [
    "**Learning Phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f112d0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 3\n",
      "1 out of 3\n",
      "2 out of 3\n",
      "3 out of 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [] #will contain the models (one per requirement)\n",
    "\n",
    "explainer = []\n",
    "\n",
    "# explanations = np.zeros((req_number, all_true_training.shape[0]), dtype=object) #will contain the explanations (objects)\n",
    "# exp_txt = [] #will contain the textual explanations its structure is a matrix (list of lists) where each row corresponds to a requirement \n",
    "#              #and each column corresponds to the explanation for the corresponding row in all_true_training_dataset\n",
    "\n",
    "\n",
    "for i in range(req_number):\n",
    "    print(f\"{i} out of {req_number-1}\")\n",
    "   \n",
    "    models.append(\\\n",
    "            sklearn.ensemble.GradientBoostingClassifier(random_state=1234))\n",
    "    models[i].fit(datasets[i].train, datasets[i].labels_train)\n",
    "    \n",
    "    #initialize the explainer\n",
    "    explainer.append(anchor_tabular.AnchorTabularExplainer(\n",
    "        datasets[i].class_names, #it maps the 0 and 1 in the dataset's requirements to the class names\n",
    "        datasets[i].feature_names,\n",
    "        datasets[i].train,\n",
    "        datasets[i].categorical_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "af58c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 training accuracy: 0.9390\n",
      "Model 2 training accuracy: 0.9035\n",
      "Model 3 training accuracy: 0.9437\n",
      "Model 4 training accuracy: 0.9293\n"
     ]
    }
   ],
   "source": [
    "for i in range(req_number):\n",
    "    print(f\"Model {i+1} training accuracy: {accuracy_score(datasets[i].labels_train, models[i].predict(datasets[i].train)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "436c4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________Requirement 1: req_0___________\n",
      "___________Requirement 2: req_1___________\n",
      "___________Requirement 3: req_2___________\n",
      "___________Requirement 4: req_3___________\n",
      "Number of samples with all requirements satisfied (according to model): 21\n",
      "Number of samples with all requirements satisfied (real data): 166\n",
      "Number of false positives from model: 3\n",
      "Number of missclassified real positives: 148\n"
     ]
    }
   ],
   "source": [
    "for i, req in enumerate(req_names):\n",
    "    print(f\"___________Requirement {i+1}: {req}___________\")\n",
    "    output = models[i].predict(datasets[i].train)\n",
    "\n",
    "    #obtain the indices of the samples that have the requirement satisfied (truly in the dataset)\n",
    "    real_values_single_req = np.where(datasets[i].labels_train == 1)[0]\n",
    "\n",
    "    if(i == 0):\n",
    "        final = np.where(output == 1)[0]\n",
    "        real_values = real_values_single_req\n",
    "    else:\n",
    "        final = np.intersect1d(final, np.where(output == 1)[0]) \n",
    "        real_values = np.intersect1d(real_values, real_values_single_req)\n",
    "\n",
    "\n",
    "positively_classified = final\n",
    "print(f\"Number of samples with all requirements satisfied (according to model): {positively_classified.shape[0]}\")\n",
    "\n",
    "print(f\"Number of samples with all requirements satisfied (real data): {real_values.shape[0]}\")\n",
    "#calulate false positives\n",
    "f_p = positively_classified.shape[0]- np.intersect1d(real_values, positively_classified).shape[0]\n",
    "print(f\"Number of false positives from model: {f_p}\")\n",
    "#calculate the missclassified real positive\n",
    "m_r_p = real_values.shape[0] - np.intersect1d(real_values, positively_classified).shape[0]\n",
    "print(f\"Number of missclassified real positives: {m_r_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d516118",
   "metadata": {},
   "source": [
    "Now we will find all points in the dataset that have not satisfied each requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "114ce1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________Requirement 1: req_0___________\n",
      "___________Requirement 2: req_1___________\n",
      "___________Requirement 3: req_2___________\n",
      "___________Requirement 4: req_3___________\n",
      "Number of samples with all requirements satisfied (according to model): 2697\n",
      "Number of samples with all requirements satisfied (real data): 3834\n",
      "Number of false negatives from model: 6\n",
      "Number of missclassified real negatives: 1143\n"
     ]
    }
   ],
   "source": [
    "for i, req in enumerate(req_names):\n",
    "    print(f\"___________Requirement {i+1}: {req}___________\")\n",
    "    output = models[i].predict(datasets[i].train)\n",
    "\n",
    "    #obtain the indices of the samples that have the requirement satisfied (truly in the dataset)\n",
    "    real_values_single_req = datasets[i].labels_train\n",
    "\n",
    "    if(i == 0):\n",
    "        final = output\n",
    "        real_values = real_values_single_req\n",
    "    else:\n",
    "        final *= final\n",
    "        real_values *= real_values_single_req\n",
    "\n",
    "negatively_classified = np.where(final == 0)[0]\n",
    "true_negative = np.where(real_values == 0)[0]\n",
    "\n",
    "print(f\"Number of samples with all requirements satisfied (according to model): {negatively_classified.shape[0]}\")\n",
    "print(f\"Number of samples with all requirements satisfied (real data): {true_negative.shape[0]}\")\n",
    "#calulate false negatives\n",
    "f_n = negatively_classified.shape[0]- np.intersect1d(true_negative, negatively_classified).shape[0]\n",
    "print(f\"Number of false negatives from model: {f_n}\")\n",
    "#calculate the missclassified real negative\n",
    "m_r_n = true_negative.shape[0] - np.intersect1d(true_negative, negatively_classified).shape[0]\n",
    "print(f\"Number of missclassified real negatives: {m_r_n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6e8d8",
   "metadata": {},
   "source": [
    "**Explain the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "04348592",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = []\n",
    "\n",
    "for j, p_sample in enumerate(positively_classified):\n",
    "    intersected_exp = {}\n",
    "    for i in range(req_number):\n",
    "        #get the sample\n",
    "        sample = datasets[i].train[p_sample]\n",
    "        #explain the sample\n",
    "        exp = explainer[i].explain_instance(sample, models[i].predict, threshold=0.95)\n",
    "        #get the textual explanation\n",
    "        exp = exp.names()\n",
    "        #transform the textual explanations in an interval\n",
    "        for boundings in exp:\n",
    "            quoted, rest = get_anchor(boundings)            \n",
    "            if(quoted not in intersected_exp):\n",
    "                intersected_exp[quoted] = parse_range(rest)\n",
    "            else:\n",
    "                intersected_exp[quoted] = intersect(intersected_exp[quoted], parse_range(rest))\n",
    "\n",
    "    #prepare the data structure\n",
    "    explanations.append(intersected_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7e248",
   "metadata": {},
   "source": [
    "Let's verify that the data structure is correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e84ea2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(explanations) == positively_classified.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "21a59df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'obstacle size': (26.74, 50.25, False, True),\n",
       "  'power': (51.0, inf, False, False),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'obstacle distance': (25.34, 49.94, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'smoke intensity': (-inf, 48.87, False, True),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'obstacle size': (74.61, inf, False, False),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'power': (25.0, 76.0, False, True),\n",
       "  'obstacle distance': (74.78, inf, False, False)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'power': (76.0, inf, False, False),\n",
       "  'obstacle size': (26.74, 50.25, False, True),\n",
       "  'controls responsiveness': (26.39, inf, False, False),\n",
       "  'obstacle distance': (-inf, 74.78, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (50.87, inf, False, False),\n",
       "  'cruise speed': (-inf, 50.17, False, True),\n",
       "  'smoke intensity': (-inf, 48.87, False, True),\n",
       "  'obstacle distance': (-inf, 25.34, False, True),\n",
       "  'power': (76.0, inf, False, False),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'obstacle size': (-inf, 26.74, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'obstacle distance': (49.94, 74.78, False, True),\n",
       "  'obstacle size': (26.74, inf, False, False),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'power': (25.0, inf, False, False)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'illuminance': (50.87, inf, False, False),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'cruise speed': (-inf, 75.49, False, True),\n",
       "  'obstacle size': (26.74, 50.25, False, True),\n",
       "  'obstacle distance': (25.34, 49.94, False, True),\n",
       "  'controls responsiveness': (50.29, inf, False, False)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'cruise speed': (-inf, 50.17, False, True),\n",
       "  'power': (25.0, inf, False, False),\n",
       "  'obstacle size': (50.25, 74.61, False, True),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'obstacle distance': (-inf, 74.78, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'image resolution': (25.4, inf, False, False),\n",
       "  'obstacle distance': (49.94, 74.78, False, True),\n",
       "  'power': (76.0, inf, False, False),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'obstacle size': (-inf, 50.25, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'power': (25.0, 76.0, False, True),\n",
       "  'obstacle distance': (49.94, 74.78, False, True),\n",
       "  'obstacle size': (74.61, inf, False, False),\n",
       "  'controls responsiveness': (73.9, inf, False, False)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'smoke intensity': (-inf, 48.87, False, True),\n",
       "  'power': (51.0, inf, False, False),\n",
       "  'obstacle distance': (25.34, 49.94, False, True),\n",
       "  'controls responsiveness': (50.29, inf, False, False),\n",
       "  'obstacle size': (-inf, 50.25, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'smoke intensity': (-inf, 48.87, False, True),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'obstacle distance': (25.34, 49.94, False, True),\n",
       "  'power': (25.0, inf, False, False),\n",
       "  'controls responsiveness': (50.29, inf, False, False),\n",
       "  'obstacle size': (50.25, 74.61, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (26.13, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'obstacle size': (26.74, 50.25, False, True),\n",
       "  'power': (51.0, inf, False, False),\n",
       "  'controls responsiveness': (50.29, inf, False, False),\n",
       "  'obstacle distance': (-inf, 74.78, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (50.87, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'smoke intensity': (-inf, 73.67, False, True),\n",
       "  'power': (76.0, inf, False, False),\n",
       "  'obstacle size': (50.25, 74.61, False, True),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'obstacle distance': (25.34, 49.94, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'image resolution': (25.4, 75.24, False, True),\n",
       "  'obstacle size': (26.74, 50.25, False, True),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'obstacle distance': (49.94, inf, False, False)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'smoke intensity': (23.42, 73.67, False, True),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'obstacle size': (26.74, inf, False, False),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'power': (25.0, inf, False, False),\n",
       "  'obstacle distance': (25.34, 49.94, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'illuminance': (50.87, inf, False, False),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'power': (25.0, inf, False, False),\n",
       "  'obstacle distance': (-inf, 49.94, False, True),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'obstacle size': (26.74, 50.25, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (50.87, inf, False, False),\n",
       "  'cruise speed': (-inf, 50.17, False, True),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'obstacle size': (74.61, inf, False, False),\n",
       "  'power': (25.0, inf, False, False),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'obstacle distance': (49.94, 74.78, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (49.8, inf, False, False),\n",
       "  'illuminance': (50.87, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'obstacle size': (74.61, inf, False, False),\n",
       "  'power': (51.0, inf, False, False),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'obstacle distance': (49.94, 74.78, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (50.87, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'power': (51.0, inf, False, False),\n",
       "  'obstacle size': (74.61, inf, False, False),\n",
       "  'controls responsiveness': (50.29, inf, False, False),\n",
       "  'obstacle distance': (25.34, 49.94, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'power': (76.0, inf, False, False),\n",
       "  'obstacle size': (50.25, 74.61, False, True),\n",
       "  'controls responsiveness': (50.29, inf, False, False),\n",
       "  'obstacle distance': (-inf, 74.78, False, True)},\n",
       " {'firm obstacle': (1.0, 1.0, True, True),\n",
       "  'image resolution': (75.24, inf, False, False),\n",
       "  'illuminance': (75.91, inf, False, False),\n",
       "  'cruise speed': (-inf, 25.21, False, True),\n",
       "  'smoke intensity': (-inf, 23.42, False, True),\n",
       "  'obstacle size': (26.74, inf, False, False),\n",
       "  'obstacle distance': (49.94, 74.78, False, True),\n",
       "  'controls responsiveness': (73.9, inf, False, False),\n",
       "  'power': (76.0, inf, False, False)}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd775a56",
   "metadata": {},
   "source": [
    "### Anchors for negative points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c727304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_explanations = []\n",
    "\n",
    "# for j, p_sample in enumerate(negatively_classified):\n",
    "#     final_exp = {}\n",
    "#     for i in range(req_number):\n",
    "#         #get the sample\n",
    "#         sample = datasets[i].train[p_sample]\n",
    "#         #explain the sample\n",
    "#         exp = explainer[i].explain_instance(sample, models[i].predict, threshold=0.95)\n",
    "#         #get the textual explanation\n",
    "#         exp = exp.names()\n",
    "#         #transform the textual explanations in an interval\n",
    "#         for boundings in exp:\n",
    "#             quoted, rest = get_anchor(boundings)            \n",
    "#             final_exp[quoted] = parse_range(rest)\n",
    "#         #update the \n",
    "#         neg_explanations.append(final_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "11a3dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(neg_explanations) == negatively_classified.shape[0]*req_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f8cba587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3488f6d",
   "metadata": {},
   "source": [
    "Now a point will be classified as positive if it's simultaniously inside the area defined by explanations and not inside the are of negative_explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b51469",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67ec5e",
   "metadata": {},
   "source": [
    "Verify if the function works properly by submitting the positively classified samples in the training dataset, we should obtain that all the input are positively classified in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cbc5f4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with req_3 classified as satisfied: 21.      \n",
      "If this number is 21 it means that the anchor function classifies correctly the samples classified true by the model.      \n",
      "In this case it is True\n"
     ]
    }
   ],
   "source": [
    "idx = positively_classified\n",
    "\n",
    "samples = datasets[0].train[idx]\n",
    "#classify the samples with the anchor function\n",
    "sat = classify_w_anchor(samples, explanations, feature_names)\n",
    "\n",
    "#obtain the indices of the samples that have the requirement satisfied\n",
    "anchors_positives = np.where(sat != 0)[0]\n",
    "print(f\"Number of samples with {req} classified as satisfied: {len(anchors_positives)}.\\\n",
    "      \\nIf this number is {len(idx)} it means that the anchor function classifies correctly the samples classified true by the model.\\\n",
    "      \\nIn this case it is {len(idx) == len(anchors_positives)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a28ad4",
   "metadata": {},
   "source": [
    "Validate the anchors classifier on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "77c17687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 13)\n"
     ]
    }
   ],
   "source": [
    "val_set = validation_df.values\n",
    "print(val_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "62937311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64.2909, 16.3241, 65.5295, 55.7508, 25.0, 28.5735, 6.1418, 89.258,\n",
       "       0.0, False, True, False, False], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "16df7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n",
      "___________Requirement req_0___________\n",
      "___________Requirement req_1___________\n",
      "___________Requirement req_2___________\n",
      "___________Requirement req_3___________\n",
      "Number of samples with all reqs classified as satisfied by the model: 7\n",
      "Number of samples with all reqs classified as satisfied by the anchor function: 5\n",
      "Number of samples with all reqs classified as satisfied by the model and the anchor function: 5\n",
      "\n",
      "\n",
      "Number of samples with all reqs classified as satisfied: 5.        \n",
      "If this number is 7 it means that the anchor function classifies correctly the samples classified true by the model.        \n",
      "In this case it is False\n",
      "Number of false positives: 0, ratio (over anchor_positives): 0.0\n",
      "Number of missclassified real positives: 2, ratio (over model_positives): 0.2857142857142857\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#obtain the samples\n",
    "samples = val_set[:, 0:feature_number]\n",
    "print(samples.shape)\n",
    "for r, req in enumerate(req_names):\n",
    "    print(f\"___________Requirement {req}___________\")\n",
    "    \n",
    "    #classify the samples with the model\n",
    "    tmp_output = models[r].predict(samples)\n",
    "    if(r == 0):\n",
    "        output = tmp_output\n",
    "    else:\n",
    "        output *= tmp_output\n",
    "\n",
    "#classify the samples with the anchor function\n",
    "sat = classify_w_anchor(samples, explanations, feature_names)\n",
    "    \n",
    "#obtain the indices of the samples that are classified as true by the model\n",
    "models_positives = np.where(output != 0)[0]\n",
    "    \n",
    "#obtain the indices of the samples that are classified as true by anchors\n",
    "anchors_positives = np.where(sat != 0)[0]\n",
    "\n",
    "#obtain the samples classified correctly by anchors w.r.t. the model\n",
    "correctly_classified = np.intersect1d(models_positives, anchors_positives)\n",
    "\n",
    "print(f\"Number of samples with all reqs classified as satisfied by the model: {len(models_positives)}\")\n",
    "print(f\"Number of samples with all reqs classified as satisfied by the anchor function: {len(anchors_positives)}\")\n",
    "print(f\"Number of samples with all reqs classified as satisfied by the model and the anchor function: {len(correctly_classified)}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Number of samples with all reqs classified as satisfied: {len(anchors_positives)}.\\\n",
    "        \\nIf this number is {len(models_positives)} it means that the anchor function classifies correctly the samples classified true by the model.\\\n",
    "        \\nIn this case it is {len(models_positives) == len(anchors_positives)}\")\n",
    "\n",
    "#calculate the false positives\n",
    "f_p = anchors_positives.shape[0] - correctly_classified.shape[0]\n",
    "print(f\"Number of false positives: {f_p}, ratio (over anchor_positives): {f_p/anchors_positives.shape[0]}\")\n",
    "\n",
    "#calculate the missclassified real positive\n",
    "m_r_p = models_positives.shape[0] - correctly_classified.shape[0]\n",
    "print(f\"Number of missclassified real positives: {m_r_p}, ratio (over model_positives): {m_r_p/models_positives.shape[0]}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a7d368ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n",
      "(1000, 4)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "non_contr_feature_names = feature_names[3:7]\n",
    "\n",
    "s = samples[:, 3:7]\n",
    "print(samples.shape)\n",
    "print(s.shape)\n",
    "\n",
    "cl = classify_w_anchor(s, explanations, non_contr_feature_names)\n",
    "\n",
    "print(cl.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "56890c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208,)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(cl != 0)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bdc60",
   "metadata": {},
   "source": [
    "# Validation using also negative area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1cc1e552",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neg_explanations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m samples \u001b[38;5;241m=\u001b[39m datasets[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtrain[idx]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#classify the samples with the anchor function\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m sat \u001b[38;5;241m=\u001b[39m classify_w_anchor(samples, \u001b[43mneg_explanations\u001b[49m, feature_names)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#obtain the indices of the samples that have the requirement satisfied\u001b[39;00m\n\u001b[1;32m      9\u001b[0m anchors_negatives \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(sat \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neg_explanations' is not defined"
     ]
    }
   ],
   "source": [
    "#obtain the negatively classified inidces\n",
    "idx = negatively_classified\n",
    "\n",
    "samples = datasets[0].train[idx]\n",
    "#classify the samples with the anchor function\n",
    "sat = classify_w_anchor(samples, neg_explanations, feature_names)\n",
    "\n",
    "#obtain the indices of the samples that have the requirement satisfied\n",
    "anchors_negatives = np.where(sat != 0)[0]\n",
    "print(f\"Number of samples with {req} classified as satisfied: {len(anchors_negatives)}.\\\n",
    "      \\nIf this number is {len(idx)} it means that the anchor function classifies correctly the samples classified true by the model.\\\n",
    "      \\nIn this case it is {len(idx) == len(anchors_negatives)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad703b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________Requirement req_0___________\n",
      "___________Requirement req_1___________\n",
      "___________Requirement req_2___________\n",
      "___________Requirement req_3___________\n",
      "Number of samples with all reqs classified as satisfied by the model: 7\n",
      "Number of samples with all reqs classified as satisfied by the anchor function: 5\n",
      "Number of samples with all reqs classified as satisfied by the model and the anchor function: 5\n",
      "\n",
      "\n",
      "Number of samples with all reqs classified as satisfied: 5.        \n",
      "If this number is 7 it means that the anchor function classifies correctly the samples classified true by the model.        \n",
      "In this case it is False\n",
      "Number of false positives: 0, ratio (over anchor_positives): 0.0\n",
      "Number of missclassified real positives: 2, ratio (over model_positives): 0.2857142857142857\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#obtain the samples\n",
    "samples = val_set[:, 0:feature_number]\n",
    "\n",
    "for r, req in enumerate(req_names):\n",
    "    print(f\"___________Requirement {req}___________\")\n",
    "    \n",
    "    #classify the samples with the model\n",
    "    tmp_output = models[r].predict(samples)\n",
    "    if(r == 0):\n",
    "        output = tmp_output\n",
    "    else:\n",
    "        output *= tmp_output\n",
    "\n",
    "#classify the positive samples with the anchor function\n",
    "pos_anch_classif = classify_w_anchor(samples, explanations, feature_names)\n",
    "\n",
    "#classify the negative samples with the anchor function\n",
    "neg_anch_classif = classify_w_anchor(samples, neg_explanations, feature_names)\n",
    "\n",
    "final_anch = pos_anch_classif * neg_anch_classif\n",
    "\n",
    "#obtain the indices of the samples that are classified as true by the model\n",
    "models_positives = np.where(output != 0)[0]\n",
    "    \n",
    "#obtain the indices of the samples that are classified as true by anchors\n",
    "anchors_positives = np.where(final_anch != 0)[0]\n",
    "\n",
    "#obtain the samples classified correctly by anchors w.r.t. the model\n",
    "correctly_classified = np.intersect1d(models_positives, anchors_positives)\n",
    "\n",
    "print(f\"Number of samples with all reqs classified as satisfied by the model: {len(models_positives)}\")\n",
    "print(f\"Number of samples with all reqs classified as satisfied by the anchor function: {len(anchors_positives)}\")\n",
    "print(f\"Number of samples with all reqs classified as satisfied by the model and the anchor function: {len(correctly_classified)}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Number of samples with all reqs classified as satisfied: {len(anchors_positives)}.\\\n",
    "        \\nIf this number is {len(models_positives)} it means that the anchor function classifies correctly the samples classified true by the model.\\\n",
    "        \\nIn this case it is {len(models_positives) == len(anchors_positives)}\")\n",
    "\n",
    "#calculate the false positives\n",
    "f_p = anchors_positives.shape[0] - correctly_classified.shape[0]\n",
    "print(f\"Number of false positives: {f_p}, ratio (over anchor_positives): {f_p/anchors_positives.shape[0]}\")\n",
    "\n",
    "#calculate the missclassified real positive\n",
    "m_r_p = models_positives.shape[0] - correctly_classified.shape[0]\n",
    "print(f\"Number of missclassified real positives: {m_r_p}, ratio (over model_positives): {m_r_p/models_positives.shape[0]}\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
