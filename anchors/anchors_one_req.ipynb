{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8bc168",
   "metadata": {},
   "source": [
    "# **Anchors on one requirement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "729a59dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from sklearn.metrics import accuracy_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab5760",
   "metadata": {},
   "source": [
    "**DF Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ce34289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  5000\n",
      "Training dataset size:  (4000, 13)\n",
      "Validation dataset size:  (1000, 13)\n",
      "Training samples with all requirements satisfied:  (156, 9)\n",
      "Validation samples with all requirements satisfied:  (49, 9)\n",
      "Training samples with req_0 satisfied:  (1382, 9)\n",
      "Training samples with req_1 satisfied:  (723, 9)\n",
      "Training samples with req_2 satisfied:  (908, 9)\n",
      "Training samples with req_3 satisfied:  (1041, 9)\n",
      "Validation samples with req_0 satisfied:  (342, 9)\n",
      "Validation samples with req_1 satisfied:  (172, 9)\n",
      "Validation samples with req_2 satisfied:  (235, 9)\n",
      "Validation samples with req_3 satisfied:  (261, 9)\n"
     ]
    }
   ],
   "source": [
    "#meta parameters\n",
    "train_percentage = 80\n",
    "val_percentage = 20\n",
    "\n",
    "req_names = ['req_0', 'req_1', 'req_2', 'req_3']\n",
    "req_number = len(req_names)\n",
    "feature_names = ['cruise speed','image resolution','illuminance','controls responsiveness','power','smoke intensity','obstacle size','obstacle distance','firm obstacle']\n",
    "feature_number = len(feature_names)\n",
    "\n",
    "training_folder = '../datasets/dataset5000.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(training_folder)\n",
    "n_samples = df.shape[0]\n",
    "print(\"Number of samples: \", n_samples)\n",
    "\n",
    "#Split 80 20 the training dataset in training anda validation to have more similar data\n",
    "indices = np.arange(0,n_samples)\n",
    "np.random.seed(1234)\n",
    "indices = np.random.permutation(indices)\n",
    "\n",
    "training_indices = indices[0:int(n_samples*train_percentage/100)]\n",
    "validation_indices = indices[int(n_samples*train_percentage/100):]\n",
    "\n",
    "training_df = df.iloc[training_indices]\n",
    "validation_df = df.iloc[validation_indices]\n",
    "print('Training dataset size: ', training_df.shape)\n",
    "print('Validation dataset size: ', validation_df.shape)\n",
    "\n",
    "#select the samples that have all the requirements satisfied\n",
    "all_true_training = training_df[\n",
    "    (training_df['req_0'] == 1) &\n",
    "    (training_df['req_1'] == 1) &\n",
    "    (training_df['req_2'] == 1) &\n",
    "    (training_df['req_3'] == 1)\n",
    "].drop(columns=req_names)\n",
    "\n",
    "all_true_validation = validation_df[\n",
    "    (validation_df['req_0'] == 1) &\n",
    "    (validation_df['req_1'] == 1) &\n",
    "    (validation_df['req_2'] == 1) &\n",
    "    (validation_df['req_3'] == 1)\n",
    "].drop(columns=req_names)\n",
    "\n",
    "print('Training samples with all requirements satisfied: ', all_true_training.shape)\n",
    "print('Validation samples with all requirements satisfied: ', all_true_validation.shape)\n",
    "\n",
    "#select the samples that have at one specific requirement satisfied\n",
    "req_true_training = {}\n",
    "for r in req_names:\n",
    "    req_true_training[r] = training_df[training_df[r] == 1].drop(columns=req_names)\n",
    "    print('Training samples with {} satisfied: '.format(r), req_true_training[r].shape)\n",
    "\n",
    "req_true_validation = {}\n",
    "for r in req_names:\n",
    "    req_true_validation[r] = validation_df[validation_df[r] == 1].drop(columns=req_names)\n",
    "    print('Validation samples with {} satisfied: '.format(r), req_true_validation[r].shape)\n",
    "\n",
    "#create a csv with the new training data and save it\n",
    "training_df.to_csv('../datasets/training_dataset.csv', index=False)\n",
    "validation_df.to_csv('../datasets/validation_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e53832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [] #will contain the datasets as needed by the anchor library\n",
    "feature_to_use = [i for i in range(feature_number)] #contains the range of features to use\n",
    "true_from_anchors_df = {}\n",
    "\n",
    "for i,r in enumerate(req_names):\n",
    "    #we load the dataset in anchors\n",
    "    datasets.append(\\\n",
    "        utils.load_csv_dataset(\\\n",
    "            training_folder, feature_number+i,\\\n",
    "            features_to_use=feature_to_use,\\\n",
    "            categorical_features=None))\n",
    "    \n",
    "    true_from_anchors_df[r] = np.nonzero(datasets[i].train[req_number-1])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a955bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = '../datasets/training_dataset.csv'\n",
    "validation_folder = '../datasets/validation_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c01e6",
   "metadata": {},
   "source": [
    "**Learning Phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f112d0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [] #will contain the models (one per requirement)\n",
    "\n",
    "explainer = []\n",
    "\n",
    "# explanations = np.zeros((req_number, all_true_training.shape[0]), dtype=object) #will contain the explanations (objects)\n",
    "# exp_txt = [] #will contain the textual explanations its structure is a matrix (list of lists) where each row corresponds to a requirement \n",
    "#              #and each column corresponds to the explanation for the corresponding row in all_true_training_dataset\n",
    "\n",
    "\n",
    "for i in range(req_number):\n",
    "    print(i)\n",
    "    #initialize and train the model\n",
    "    #if i == 1:\n",
    "    #    models.append(\\\n",
    "    #    HistGradientBoostingClassifier(class_weight='balanced',random_state=1234))\n",
    "    #    models[i].fit(datasets[i].train, datasets[i].labels_train)\n",
    "            #models.append(\\\n",
    "        #    MLPClassifier(random_state=1234))\n",
    "        #models[i].fit(datasets[i].train, datasets[i].labels_train)\n",
    "\n",
    "    #else:\n",
    "    #    models.append(\\\n",
    "    #        sklearn.ensemble.GradientBoostingClassifier(random_state=1234))\n",
    "    #    models[i].fit(datasets[i].train, datasets[i].labels_train)\n",
    "\n",
    "    models.append(\\\n",
    "            sklearn.ensemble.GradientBoostingClassifier(random_state=1234))\n",
    "    models[i].fit(datasets[i].train, datasets[i].labels_train)\n",
    "    \n",
    "    #initialize the explainer\n",
    "    explainer.append(anchor_tabular.AnchorTabularExplainer(\n",
    "        datasets[i].class_names, #it maps the 0 and 1 in the dataset's requirements to the class names\n",
    "        datasets[i].feature_names,\n",
    "        datasets[i].train,\n",
    "        datasets[i].categorical_names))\n",
    "        \n",
    "    # #explain only points satisfying all the requirements\n",
    "    # names = []\n",
    "    \n",
    "    # for j in range():\n",
    "    #     exp = explainer.explain_instance(all_true_training.iloc[j].values.reshape(1, -1), models[i].predict, threshold=0.95) #0.95\n",
    "    #     explanations[i,j] = exp\n",
    "    #     names.append(exp.names())        \n",
    "    \n",
    "    # exp_txt.append(names)\n",
    "    \n",
    "    # print(exp_txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af58c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 training accuracy: 0.9403\n",
      "Model 2 training accuracy: 0.9081\n",
      "Model 3 training accuracy: 0.9463\n",
      "Model 4 training accuracy: 0.9294\n"
     ]
    }
   ],
   "source": [
    "for i in range(req_number):\n",
    "    print(f\"Model {i+1} training accuracy: {accuracy_score(datasets[i].labels_train, models[i].predict(datasets[i].train)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "436c4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________Requirement 1: req_0___________\n",
      "Number of samples with req_0 classified as satisfied: 1063\n",
      "Number of samples with req_0 truly satisfied: 9\n",
      "Number of false positives: 1059\n",
      "Number of missclassified real positives: 5\n",
      "___________Requirement 2: req_1___________\n",
      "Number of samples with req_1 classified as satisfied: 415\n",
      "Number of samples with req_1 truly satisfied: 9\n",
      "Number of false positives: 415\n",
      "Number of missclassified real positives: 9\n",
      "___________Requirement 3: req_2___________\n",
      "Number of samples with req_2 classified as satisfied: 622\n",
      "Number of samples with req_2 truly satisfied: 9\n",
      "Number of false positives: 621\n",
      "Number of missclassified real positives: 8\n",
      "___________Requirement 4: req_3___________\n",
      "Number of samples with req_3 classified as satisfied: 681\n",
      "Number of samples with req_3 truly satisfied: 9\n",
      "Number of false positives: 680\n",
      "Number of missclassified real positives: 8\n"
     ]
    }
   ],
   "source": [
    "training_df_out = []\n",
    "positively_classified = {}\n",
    "\n",
    "for i, req in enumerate(req_names):\n",
    "    print(f\"___________Requirement {i+1}: {req}___________\")\n",
    "    output = models[i].predict(datasets[i].train)\n",
    "    \n",
    "    #obtain the indices of the samples that have the requirement satisfied\n",
    "    indices = np.where(output == 1)[0]\n",
    "\n",
    "    print(f\"Number of samples with {req} classified as satisfied: {len(indices)}\")\n",
    "    print(f\"Number of samples with {req} truly satisfied: {len(true_from_anchors_df[req])}\")\n",
    "    \n",
    "    #calulate false positives\n",
    "    f_p = indices.shape[0] - np.intersect1d(indices, true_from_anchors_df[req]).shape[0]\n",
    "    print(f\"Number of false positives: {f_p}\")\n",
    "    #calculate the missclassified real positive\n",
    "    m_r_p = true_from_anchors_df[req].shape[0] - np.intersect1d(indices, true_from_anchors_df[req]).shape[0]\n",
    "    print(f\"Number of missclassified real positives: {m_r_p}\")\n",
    "\n",
    "    positively_classified[req] = indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da0bb9",
   "metadata": {},
   "source": [
    "**Define useful data-wrangling functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae36ae",
   "metadata": {},
   "source": [
    "function separating the name of the feature from the ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8ec5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor(a):\n",
    "    quoted_part = a.split(\"'\")[1]\n",
    "    rest = a.replace(f\"'{quoted_part}'\", '').replace(\"b\", '').strip()\n",
    "\n",
    "    return quoted_part, rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2a6cc",
   "metadata": {},
   "source": [
    "function creating the intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6363f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import inf\n",
    "\n",
    "def parse_range(expr: str):\n",
    "    expr = expr.strip().replace(\" \", \"\")\n",
    "    \n",
    "    patterns = [\n",
    "        (r\"^=(\\-?\\d+(\\.\\d+)?)$\", 'equals'),\n",
    "        (r\"^(>=|>)\\s*(-?\\d+(\\.\\d+)?)$\", 'lower'),\n",
    "        (r\"^(<=|<)\\s*(-?\\d+(\\.\\d+)?)$\", 'upper'),\n",
    "        (r\"^(-?\\d+(\\.\\d+)?)(<=|<){1,2}(<=|<)(-?\\d+(\\.\\d+)?)$\", 'between'),\n",
    "        (r\"^(-?\\d+(\\.\\d+)?)(>=|>){1,2}(>=|>)(-?\\d+(\\.\\d+)?)$\", 'reverse_between'),\n",
    "    ]\n",
    "    \n",
    "    for pattern, kind in patterns:\n",
    "        match = re.match(pattern, expr)\n",
    "        if match:\n",
    "            if kind == 'equals':\n",
    "                num = float(match.group(1))\n",
    "                return (num, num, True, True)\n",
    "            elif kind == 'lower':\n",
    "                op, num = match.group(1), float(match.group(2))\n",
    "                return (\n",
    "                    num,\n",
    "                    inf,\n",
    "                    op == '>=',\n",
    "                    False\n",
    "                )\n",
    "            elif kind == 'upper':\n",
    "                op, num = match.group(1), float(match.group(2))\n",
    "                return (\n",
    "                    -inf,\n",
    "                    num,\n",
    "                    False,\n",
    "                    op == '<='\n",
    "                )\n",
    "            elif kind == 'between':\n",
    "                low = float(match.group(1))\n",
    "                op1 = match.group(3)\n",
    "                op2 = match.group(4)\n",
    "                high = float(match.group(5))\n",
    "                return (\n",
    "                    low,\n",
    "                    high,\n",
    "                    op1 == '<=',\n",
    "                    op2 == '<='\n",
    "                )\n",
    "            elif kind == 'reverse_between':\n",
    "                high = float(match.group(1))\n",
    "                op1 = match.group(3)\n",
    "                op2 = match.group(4)\n",
    "                low = float(match.group(5))\n",
    "                return (\n",
    "                    low,\n",
    "                    high,\n",
    "                    op2 == '>=',\n",
    "                    op1 == '>='\n",
    "                )\n",
    "\n",
    "    raise ValueError(f\"Unrecognized format: {expr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3bd74a",
   "metadata": {},
   "source": [
    "function that return the truth value of a num (val) being inside a given interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "59d4c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside(val, interval):\n",
    "    low, high, li, ui = interval\n",
    "    if li and ui:\n",
    "        return low <= val <= high\n",
    "    elif li and not ui:\n",
    "        return low <= val < high\n",
    "    elif not li and ui:\n",
    "        return low < val <= high\n",
    "    else:\n",
    "        return low < val < high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c5484a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_w_anchor(input, thresholds, feature_names):\n",
    "    out = np.zeros((input.shape[0], input.shape[1]), dtype=object)\n",
    "    \n",
    "    for i in range(input.shape[0]):\n",
    "        for j in range(len(thresholds)):\n",
    "            flag = True\n",
    "            for k in feature_names:\n",
    "                if k in thresholds[j]:\n",
    "                    if not (inside(input.iloc[i][k], thresholds[j][k])):\n",
    "                        flag = False\n",
    "                        break\n",
    "            if flag:\n",
    "                out[i][j] = input.iloc[i]\n",
    "                break\n",
    "            else:\n",
    "                flag = True\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f676d",
   "metadata": {},
   "source": [
    "**Wrangle the data to cope better with them**\n",
    "\n",
    "Transform exp_txt in exp_dict a list of 4 dictionaries per element (one per requirement) in which are listed each feature with the respective constraints (as a range data structure)\n",
    "The range data structure is a 4-element tuple (float, float, boolean, boolean) where (a,b,x,y) num $\\in$ (a,b) and x and y are true if the extremes are included, otherwise they are false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fdee7475",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m exp_dict \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mexp_txt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)):\n\u001b[1;32m      3\u001b[0m     exp_dict\u001b[38;5;241m.\u001b[39mappend([{}, {}, {}, {}])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(req_names)):\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "exp_dict =[]\n",
    "for i in range(len(exp_txt[0])):\n",
    "    exp_dict.append([{}, {}, {}, {}])\n",
    "    for j in range(len(req_names)):\n",
    "        for k in range(len(exp_txt[j][i])):\n",
    "            quoted, rest = get_anchor(exp_txt[j][i][k])\n",
    "            exp_dict[i][j][quoted] = parse_range(rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692a302",
   "metadata": {},
   "source": [
    "**Assess the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef4b628",
   "metadata": {},
   "source": [
    "metaparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baa73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samples_num = v.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5fe54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
