{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8bc168",
   "metadata": {},
   "source": [
    "# **Anchors on one requirement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729a59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from sklearn.metrics import accuracy_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1801e",
   "metadata": {},
   "source": [
    "**Define useful data-wrangling functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8de2d",
   "metadata": {},
   "source": [
    "function separating the name of the feature from the ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93401316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor(a):\n",
    "    quoted_part = a.split(\"'\")[1]\n",
    "    rest = a.replace(f\"'{quoted_part}'\", '').replace(\"b\", '').strip()\n",
    "\n",
    "    return quoted_part, rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f100666",
   "metadata": {},
   "source": [
    "function creating the intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0f91abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import inf\n",
    "\n",
    "def parse_range(expr: str):\n",
    "    expr = expr.strip().replace(\" \", \"\")\n",
    "    \n",
    "    patterns = [\n",
    "        (r\"^=(\\-?\\d+(\\.\\d+)?)$\", 'equals'),\n",
    "        (r\"^(>=|>)\\s*(-?\\d+(\\.\\d+)?)$\", 'lower'),\n",
    "        (r\"^(<=|<)\\s*(-?\\d+(\\.\\d+)?)$\", 'upper'),\n",
    "        (r\"^(-?\\d+(\\.\\d+)?)(<=|<){1,2}(<=|<)(-?\\d+(\\.\\d+)?)$\", 'between'),\n",
    "        (r\"^(-?\\d+(\\.\\d+)?)(>=|>){1,2}(>=|>)(-?\\d+(\\.\\d+)?)$\", 'reverse_between'),\n",
    "    ]\n",
    "    \n",
    "    for pattern, kind in patterns:\n",
    "        match = re.match(pattern, expr)\n",
    "        if match:\n",
    "            if kind == 'equals':\n",
    "                num = float(match.group(1))\n",
    "                return (num, num, True, True)\n",
    "            elif kind == 'lower':\n",
    "                op, num = match.group(1), float(match.group(2))\n",
    "                return (\n",
    "                    num,\n",
    "                    inf,\n",
    "                    op == '>=',\n",
    "                    False\n",
    "                )\n",
    "            elif kind == 'upper':\n",
    "                op, num = match.group(1), float(match.group(2))\n",
    "                return (\n",
    "                    -inf,\n",
    "                    num,\n",
    "                    False,\n",
    "                    op == '<='\n",
    "                )\n",
    "            elif kind == 'between':\n",
    "                low = float(match.group(1))\n",
    "                op1 = match.group(3)\n",
    "                op2 = match.group(4)\n",
    "                high = float(match.group(5))\n",
    "                return (\n",
    "                    low,\n",
    "                    high,\n",
    "                    op1 == '<=',\n",
    "                    op2 == '<='\n",
    "                )\n",
    "            elif kind == 'reverse_between':\n",
    "                high = float(match.group(1))\n",
    "                op1 = match.group(3)\n",
    "                op2 = match.group(4)\n",
    "                low = float(match.group(5))\n",
    "                return (\n",
    "                    low,\n",
    "                    high,\n",
    "                    op2 == '>=',\n",
    "                    op1 == '>='\n",
    "                )\n",
    "\n",
    "    raise ValueError(f\"Unrecognized format: {expr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5573a",
   "metadata": {},
   "source": [
    "function that return the truth value of a num (val) being inside a given interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25c6710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside(val, interval):\n",
    "    low, high, li, ui = interval\n",
    "    if li and ui:\n",
    "        return low <= val <= high\n",
    "    elif li and not ui:\n",
    "        return low <= val < high\n",
    "    elif not li and ui:\n",
    "        return low < val <= high\n",
    "    else:\n",
    "        return low < val < high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a99e48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_w_anchor(input, thresholds, feature_names):\n",
    "    out = np.zeros((input.shape[0], input.shape[1]), dtype=object)\n",
    "    \n",
    "    for i in range(input.shape[0]):\n",
    "        for j in range(len(thresholds)):\n",
    "            flag = True\n",
    "            for k in feature_names:\n",
    "                if k in thresholds[j]:\n",
    "                    if not (inside(input.iloc[i][k], thresholds[j][k])):\n",
    "                        flag = False\n",
    "                        break\n",
    "            if flag:\n",
    "                out[i][j] = input.iloc[i]\n",
    "                break\n",
    "            else:\n",
    "                flag = True\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab5760",
   "metadata": {},
   "source": [
    "**DF Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce34289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  5000\n",
      "Training dataset size:  (4000, 13)\n",
      "Validation dataset size:  (1000, 13)\n",
      "Training samples with all requirements satisfied:  (156, 9)\n",
      "Validation samples with all requirements satisfied:  (49, 9)\n",
      "Training samples with req_0 satisfied:  (1382, 9)\n",
      "Training samples with req_1 satisfied:  (723, 9)\n",
      "Training samples with req_2 satisfied:  (908, 9)\n",
      "Training samples with req_3 satisfied:  (1041, 9)\n",
      "Validation samples with req_0 satisfied:  (342, 9)\n",
      "Validation samples with req_1 satisfied:  (172, 9)\n",
      "Validation samples with req_2 satisfied:  (235, 9)\n",
      "Validation samples with req_3 satisfied:  (261, 9)\n"
     ]
    }
   ],
   "source": [
    "#meta parameters\n",
    "train_percentage = 80\n",
    "val_percentage = 20\n",
    "\n",
    "req_names = ['req_0', 'req_1', 'req_2', 'req_3']\n",
    "req_number = len(req_names)\n",
    "feature_names = ['cruise speed','image resolution','illuminance','controls responsiveness','power','smoke intensity','obstacle size','obstacle distance','firm obstacle']\n",
    "feature_number = len(feature_names)\n",
    "\n",
    "training_folder = '../datasets/dataset5000.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(training_folder)\n",
    "n_samples = df.shape[0]\n",
    "print(\"Number of samples: \", n_samples)\n",
    "\n",
    "#Split 80 20 the training dataset in training anda validation to have more similar data\n",
    "indices = np.arange(0,n_samples)\n",
    "np.random.seed(1234)\n",
    "indices = np.random.permutation(indices)\n",
    "\n",
    "training_indices = indices[0:int(n_samples*train_percentage/100)]\n",
    "validation_indices = indices[int(n_samples*train_percentage/100):]\n",
    "\n",
    "training_df = df.iloc[training_indices]\n",
    "validation_df = df.iloc[validation_indices]\n",
    "print('Training dataset size: ', training_df.shape)\n",
    "print('Validation dataset size: ', validation_df.shape)\n",
    "\n",
    "#select the samples that have all the requirements satisfied\n",
    "all_true_training = training_df[\n",
    "    (training_df['req_0'] == 1) &\n",
    "    (training_df['req_1'] == 1) &\n",
    "    (training_df['req_2'] == 1) &\n",
    "    (training_df['req_3'] == 1)\n",
    "].drop(columns=req_names)\n",
    "\n",
    "all_true_validation = validation_df[\n",
    "    (validation_df['req_0'] == 1) &\n",
    "    (validation_df['req_1'] == 1) &\n",
    "    (validation_df['req_2'] == 1) &\n",
    "    (validation_df['req_3'] == 1)\n",
    "].drop(columns=req_names)\n",
    "\n",
    "print('Training samples with all requirements satisfied: ', all_true_training.shape)\n",
    "print('Validation samples with all requirements satisfied: ', all_true_validation.shape)\n",
    "\n",
    "#select the samples that have at one specific requirement satisfied\n",
    "req_true_training = {}\n",
    "for r in req_names:\n",
    "    req_true_training[r] = training_df[training_df[r] == 1].drop(columns=req_names)\n",
    "    print('Training samples with {} satisfied: '.format(r), req_true_training[r].shape)\n",
    "\n",
    "req_true_validation = {}\n",
    "for r in req_names:\n",
    "    req_true_validation[r] = validation_df[validation_df[r] == 1].drop(columns=req_names)\n",
    "    print('Validation samples with {} satisfied: '.format(r), req_true_validation[r].shape)\n",
    "\n",
    "#create a csv with the new training data and save it\n",
    "training_df.to_csv('../datasets/training_dataset.csv', index=False)\n",
    "validation_df.to_csv('../datasets/validation_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e53832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples with req_0 satisfied:  (1365,)\n",
      "Training samples with req_1 satisfied:  (725,)\n",
      "Training samples with req_2 satisfied:  (903,)\n",
      "Training samples with req_3 satisfied:  (1029,)\n"
     ]
    }
   ],
   "source": [
    "datasets = [] #will contain the datasets as needed by the anchor library\n",
    "feature_to_use = [i for i in range(feature_number)] #contains the range of features to use\n",
    "true_from_anchors_df = {}\n",
    "\n",
    "for i,r in enumerate(req_names):\n",
    "    #we load the dataset in anchors\n",
    "    datasets.append(\\\n",
    "        utils.load_csv_dataset(\\\n",
    "            training_folder, feature_number+i,\\\n",
    "            features_to_use=feature_to_use,\\\n",
    "            categorical_features=None))\n",
    "    \n",
    "    true_from_anchors_df[r] = np.nonzero(datasets[i].labels_train)[0]\n",
    "    print('Training samples with {} satisfied: '.format(r), true_from_anchors_df[r].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a955bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = '../datasets/training_dataset.csv'\n",
    "validation_folder = '../datasets/validation_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c01e6",
   "metadata": {},
   "source": [
    "**Learning Phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f112d0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [] #will contain the models (one per requirement)\n",
    "\n",
    "explainer = []\n",
    "\n",
    "# explanations = np.zeros((req_number, all_true_training.shape[0]), dtype=object) #will contain the explanations (objects)\n",
    "# exp_txt = [] #will contain the textual explanations its structure is a matrix (list of lists) where each row corresponds to a requirement \n",
    "#              #and each column corresponds to the explanation for the corresponding row in all_true_training_dataset\n",
    "\n",
    "\n",
    "for i in range(req_number):\n",
    "    print(i)\n",
    "    #initialize and train the model\n",
    "    #if i == 1:\n",
    "    #    models.append(\\\n",
    "    #    HistGradientBoostingClassifier(class_weight='balanced',random_state=1234))\n",
    "    #    models[i].fit(datasets[i].train, datasets[i].labels_train)\n",
    "            #models.append(\\\n",
    "        #    MLPClassifier(random_state=1234))\n",
    "        #models[i].fit(datasets[i].train, datasets[i].labels_train)\n",
    "\n",
    "    #else:\n",
    "    #    models.append(\\\n",
    "    #        sklearn.ensemble.GradientBoostingClassifier(random_state=1234))\n",
    "    #    models[i].fit(datasets[i].train, datasets[i].labels_train)\n",
    "\n",
    "    models.append(\\\n",
    "            sklearn.ensemble.GradientBoostingClassifier(random_state=1234))\n",
    "    models[i].fit(datasets[i].train, datasets[i].labels_train)\n",
    "    \n",
    "    #initialize the explainer\n",
    "    explainer.append(anchor_tabular.AnchorTabularExplainer(\n",
    "        datasets[i].class_names, #it maps the 0 and 1 in the dataset's requirements to the class names\n",
    "        datasets[i].feature_names,\n",
    "        datasets[i].train,\n",
    "        datasets[i].categorical_names))\n",
    "        \n",
    "    # #explain only points satisfying all the requirements\n",
    "    # names = []\n",
    "    \n",
    "    # for j in range():\n",
    "    #     exp = explainer.explain_instance(all_true_training.iloc[j].values.reshape(1, -1), models[i].predict, threshold=0.95) #0.95\n",
    "    #     explanations[i,j] = exp\n",
    "    #     names.append(exp.names())        \n",
    "    \n",
    "    # exp_txt.append(names)\n",
    "    \n",
    "    # print(exp_txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af58c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 training accuracy: 0.9390\n",
      "Model 2 training accuracy: 0.9035\n",
      "Model 3 training accuracy: 0.9437\n",
      "Model 4 training accuracy: 0.9293\n"
     ]
    }
   ],
   "source": [
    "for i in range(req_number):\n",
    "    print(f\"Model {i+1} training accuracy: {accuracy_score(datasets[i].labels_train, models[i].predict(datasets[i].train)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________Requirement 1: req_0___________\n",
      "Number of samples with req_0 classified as satisfied: 1303\n",
      "Number of samples with req_0 truly satisfied: 1365\n",
      "Number of false positives: 91\n",
      "Number of missclassified real positives: 153\n",
      "\n",
      "\n",
      "___________Requirement 2: req_1___________\n",
      "Number of samples with req_1 classified as satisfied: 537\n",
      "Number of samples with req_1 truly satisfied: 725\n",
      "Number of false positives: 99\n",
      "Number of missclassified real positives: 287\n",
      "\n",
      "\n",
      "___________Requirement 3: req_2___________\n",
      "Number of samples with req_2 classified as satisfied: 752\n",
      "Number of samples with req_2 truly satisfied: 903\n",
      "Number of false positives: 37\n",
      "Number of missclassified real positives: 188\n",
      "\n",
      "\n",
      "___________Requirement 4: req_3___________\n",
      "Number of samples with req_3 classified as satisfied: 820\n",
      "Number of samples with req_3 truly satisfied: 1029\n",
      "Number of false positives: 37\n",
      "Number of missclassified real positives: 246\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df_out = []\n",
    "positively_classified = {} #contains the INDICES (w.r.t. datasets[req_i_num]) of the samples classified positively by the model. \n",
    "                           #Note: TEHSE MIGHT BE SLIGHTLY DIFFERENT FROM THOSE TRUE IN THE Dataset depending on the accuracy of the model\n",
    "\n",
    "for i, req in enumerate(req_names):\n",
    "    print(f\"___________Requirement {i+1}: {req}___________\")\n",
    "    output = models[i].predict(datasets[i].train)\n",
    "    \n",
    "    #obtain the indices of the samples that have the requirement satisfied\n",
    "    indices = np.where(output == 1)[0]\n",
    "\n",
    "    print(f\"Number of samples with {req} classified as satisfied: {len(indices)}\")\n",
    "    print(f\"Number of samples with {req} truly satisfied: {len(true_from_anchors_df[req])}\")\n",
    "    \n",
    "    #calulate false positives\n",
    "    f_p = indices.shape[0] - np.intersect1d(indices, true_from_anchors_df[req]).shape[0]\n",
    "    print(f\"Number of false positives: {f_p}\")\n",
    "    #calculate the missclassified real positive\n",
    "    m_r_p = true_from_anchors_df[req].shape[0] - np.intersect1d(indices, true_from_anchors_df[req]).shape[0]\n",
    "    print(f\"Number of missclassified real positives: {m_r_p}\")\n",
    "\n",
    "    positively_classified[req] = indices\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6e8d8",
   "metadata": {},
   "source": [
    "**Explain the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11c061ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer[0].explain_instance(datasets[0].train[positively_classified[req_names[0]][0]], models[0].predict, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f887ee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1303,)\n"
     ]
    }
   ],
   "source": [
    "array = np.zeros_like(positively_classified[req_names[0]])\n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04348592",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m sample \u001b[38;5;241m=\u001b[39m datasets[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtrain[p_sample]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#explain the sample\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#get the textual explanation\u001b[39;00m\n\u001b[1;32m     12\u001b[0m exp \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mnames()\n",
      "File \u001b[0;32m~/Documents/GitHub.nosync/XDA1.4/venv/lib/python3.11/site-packages/anchor/anchor_tabular.py:278\u001b[0m, in \u001b[0;36mAnchorTabularExplainer.explain_instance\u001b[0;34m(self, data_row, classifier_fn, threshold, delta, tau, batch_size, max_anchor_size, desired_label, beam_size, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m sample_fn, mapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sample_fn(\n\u001b[1;32m    276\u001b[0m     data_row, classifier_fn, desired_label\u001b[38;5;241m=\u001b[39mdesired_label)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# return sample_fn, mapping\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43manchor_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAnchorBaseBeam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manchor_beam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesired_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_anchor_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_anchor_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_names_to_exp(data_row, exp, mapping)\n\u001b[1;32m    283\u001b[0m exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_row\n",
      "File \u001b[0;32m~/Documents/GitHub.nosync/XDA1.4/venv/lib/python3.11/site-packages/anchor/anchor_base.py:314\u001b[0m, in \u001b[0;36mAnchorBaseBeam.anchor_beam\u001b[0;34m(sample_fn, delta, epsilon, batch_size, min_shared_samples, desired_confidence, beam_size, verbose, epsilon_stop, min_samples_start, max_anchor_size, verbose_every, stop_on_first, coverage_samples)\u001b[0m\n\u001b[1;32m    311\u001b[0m initial_stats \u001b[38;5;241m=\u001b[39m AnchorBaseBeam\u001b[38;5;241m.\u001b[39mget_initial_statistics(tuples,\n\u001b[1;32m    312\u001b[0m                                                       state)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# print tuples, beam_size\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m chosen_tuples \u001b[38;5;241m=\u001b[39m \u001b[43mAnchorBaseBeam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlucb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbeam_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtuples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m best_of_size[current_size] \u001b[38;5;241m=\u001b[39m [tuples[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m chosen_tuples]\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/Documents/GitHub.nosync/XDA1.4/venv/lib/python3.11/site-packages/anchor/anchor_base.py:72\u001b[0m, in \u001b[0;36mAnchorBaseBeam.lucb\u001b[0;34m(sample_fns, initial_stats, epsilon, delta, batch_size, top_n, verbose, verbose_every)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(n_samples \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     71\u001b[0m     n_samples[f] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 72\u001b[0m     positives[f] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msample_fns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m==\u001b[39m top_n:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_features)\n",
      "File \u001b[0;32m~/Documents/GitHub.nosync/XDA1.4/venv/lib/python3.11/site-packages/anchor/anchor_base.py:201\u001b[0m, in \u001b[0;36mAnchorBaseBeam.get_sample_fns.<locals>.<lambda>\u001b[0;34m(n, t)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tuples:\n\u001b[0;32m--> 201\u001b[0m     sample_fns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mlambda\u001b[39;00m n, t\u001b[38;5;241m=\u001b[39mt: \u001b[43mcomplete_sample_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample_fns\n",
      "File \u001b[0;32m~/Documents/GitHub.nosync/XDA1.4/venv/lib/python3.11/site-packages/anchor/anchor_base.py:171\u001b[0m, in \u001b[0;36mAnchorBaseBeam.get_sample_fns.<locals>.complete_sample_fn\u001b[0;34m(t, n)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcomplete_sample_fn\u001b[39m(t, n):\n\u001b[0;32m--> 171\u001b[0m     raw_data, data, labels \u001b[38;5;241m=\u001b[39m \u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     current_idx \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# idxs = range(state['data'].shape[0], state['data'].shape[0] + n)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub.nosync/XDA1.4/venv/lib/python3.11/site-packages/anchor/anchor_tabular.py:250\u001b[0m, in \u001b[0;36mAnchorTabularExplainer.get_sample_fn.<locals>.sample_fn\u001b[0;34m(present, num_samples, compute_labels)\u001b[0m\n\u001b[1;32m    248\u001b[0m         conditions_geq[f] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(conditions_geq[f], v)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# conditions_eq = dict([(x, data_row[x]) for x in present])\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_from_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconditions_eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditions_geq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditions_leq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m d_raw_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisc\u001b[38;5;241m.\u001b[39mdiscretize(raw_data)\n\u001b[1;32m    253\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_samples, \u001b[38;5;28mlen\u001b[39m(mapping)), \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub.nosync/XDA1.4/venv/lib/python3.11/site-packages/anchor/anchor_tabular.py:104\u001b[0m, in \u001b[0;36mAnchorTabularExplainer.sample_from_train\u001b[0;34m(self, conditions_eq, conditions_neq, conditions_geq, conditions_leq, num_samples)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    103\u001b[0m idx \u001b[38;5;241m=\u001b[39m d_sample[:, f] \u001b[38;5;241m>\u001b[39m conditions_leq[f]\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43midx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    106\u001b[0m options \u001b[38;5;241m=\u001b[39m d_train[:, f] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m conditions_leq[f]\n",
      "File \u001b[0;32m~/Documents/GitHub.nosync/XDA1.4/venv/lib/python3.11/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "explanations = [[] for req in range(req_number)]\n",
    "\n",
    "for i, req in enumerate(req_names):\n",
    "    for j, p_sample in enumerate(positively_classified[req]):\n",
    "        #prepare the data structure\n",
    "        explanations[i].append({})\n",
    "        #get the sample\n",
    "        sample = datasets[0].train[p_sample]\n",
    "        #explain the sample\n",
    "        exp = explainer[i].explain_instance(sample, models[i].predict, threshold=0.95)\n",
    "        #get the textual explanation\n",
    "        exp = exp.names()\n",
    "        #transform the textuql explanations in an interval\n",
    "        for boundings in exp:\n",
    "            quoted, rest = get_anchor(boundings)\n",
    "            explanations[i][j][quoted] =rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7e248",
   "metadata": {},
   "source": [
    "Let's verify that the data structure is correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ea2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explanations.len() == req_number)\n",
    "\n",
    "for i, r in enumerate(req_names):\n",
    "    print(f\"req{i}, {len(explanations[i])}\")\n",
    "    print(len(explanations[i]) == positively_classified[r].shape, positively_classified[r].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f676d",
   "metadata": {},
   "source": [
    "**Wrangle the data to cope better with them**\n",
    "\n",
    "Transform exp_txt in exp_dict a list of 4 dictionaries per element (one per requirement) in which are listed each feature with the respective constraints (as a range data structure)\n",
    "The range data structure is a 4-element tuple (float, float, boolean, boolean) where (a,b,x,y) num $\\in$ (a,b) and x and y are true if the extremes are included, otherwise they are false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee7475",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m exp_dict \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mexp_txt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)):\n\u001b[1;32m      3\u001b[0m     exp_dict\u001b[38;5;241m.\u001b[39mappend([{}, {}, {}, {}])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(req_names)):\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "exp_dict =[]\n",
    "for i in range(len(exp_txt[0])):\n",
    "    exp_dict.append([{}, {}, {}, {}])\n",
    "    for j in range(len(req_names)):\n",
    "        for k in range(len(exp_txt[j][i])):\n",
    "            quoted, rest = get_anchor(exp_txt[j][i][k])\n",
    "            exp_dict[i][j][quoted] = parse_range(rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692a302",
   "metadata": {},
   "source": [
    "**Assess the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef4b628",
   "metadata": {},
   "source": [
    "metaparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baa73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samples_num = v.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5fe54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
